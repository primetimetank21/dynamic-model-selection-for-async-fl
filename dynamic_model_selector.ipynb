{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c17936-35dc-4d71-a35f-c350e69d4f16",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f5ad90-4814-46fe-bd51-44a3783ce348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional, Dict, List\n",
    "\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5a1400-71b5-4daf-845c-92e92b113e0e",
   "metadata": {},
   "source": [
    "# Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce713305-42f6-4642-8766-a78605ba4e98",
   "metadata": {},
   "source": [
    "1. Get paths of models (given a directory)\n",
    "1. Store paths of models\n",
    "1. For each model...\n",
    "   1. Load into memory\n",
    "   2. Test model\n",
    "   3. Compare to the current best models for each performance metric, replacing if necessary\n",
    "1. Save best models to `best_models.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afaa7ca-6c3a-4399-abb1-28fdb3b76018",
   "metadata": {},
   "source": [
    "# Dynamically Selecting the Best Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9d633b-6096-4b58-9115-06330feb2cfb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Get paths of models (given a directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc8302-d1bf-4742-a56c-f712bbd52b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIO: str = \"best\"  # the scenario we're interested in\n",
    "SEED: int = 0  # the seed of the experiment we're interested in analyzing\n",
    "chosen_scenario_dir: Optional[Path] = None\n",
    "experiment_run_dir: Path = Path(\n",
    "    Path.cwd(), \"save\", \"coba_legacy\"\n",
    ")  # could also be: \"coba\", \"mnist\", \"cifar10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9436e9-122c-4be3-98f2-ecbba1ea97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get models according to the chosen scenario\n",
    "async_fl_scenarios: Dict[str, str] = {\"0.3\": \"best\", \"0.5\": \"average\", \"1.0\": \"worst\"}\n",
    "\n",
    "print(\"Async FL Scenarios:\")\n",
    "for dir in experiment_run_dir.glob(\"*\"):\n",
    "    scenario_percent: str = (\n",
    "        dir.as_posix().split(os.sep)[-1].split(\"_\")[-2].replace(\"C\", \"\")\n",
    "    )\n",
    "    print(f\"\\t{scenario_percent} -> {async_fl_scenarios[scenario_percent]}\")\n",
    "\n",
    "    if async_fl_scenarios[scenario_percent] == SCENARIO:\n",
    "        chosen_scenario_dir = dir\n",
    "\n",
    "print(f\"{SCENARIO.title()} case scenario directory: '{chosen_scenario_dir.as_posix()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636294ce-7210-439d-9046-d207bb498b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths to models in the chosen scenario\n",
    "all_chosen_scenario_runs_dir: Path = Path(chosen_scenario_dir, \"shard2\")\n",
    "all_models_dir: Optional[Path] = None\n",
    "\n",
    "for dir in all_chosen_scenario_runs_dir.glob(\"*\"):\n",
    "    seed: int = int(dir.as_posix().split(os.sep)[-1].split(\"_\")[0].split(\"d\")[-1])\n",
    "\n",
    "    if SEED == seed:\n",
    "        all_models_dir = Path(dir, \"fed\")\n",
    "\n",
    "# Raise error if no directory is found with the given SEED\n",
    "if all_models_dir is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Directory with the provided seed '{SEED}' does not exist. Please choose a different one and try again.\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(\n",
    "    [\n",
    "        model_file.as_posix().split(os.sep)[-1]\n",
    "        for model_file in all_models_dir.glob(\"*.pt\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f12f7d-041a-452f-814c-f77c4cf4b174",
   "metadata": {},
   "source": [
    "## 2. Store paths of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f441c9-f502-43b7-b59e-deb8909050ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_paths:List[Path] = sorted([model_file for model_file in all_models_dir.glob(\"*.pt\")],key=lambda s: int(s.as_posix().split(os.sep)[-1].split(\"_\")[-1].replace(\".pt\",\"\")))\n",
    "model_paths: List[Path] = [model_file for model_file in all_models_dir.glob(\"*.pt\")]\n",
    "model_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde7041-43b2-423a-82a5-0baa7f69352f",
   "metadata": {},
   "source": [
    "## 3. For each model..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fa2281",
   "metadata": {},
   "source": [
    "1. Load into memory\n",
    "2. Test model\n",
    "3. Compare to the current best models for each performance metric, replacing if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa3f9a-283e-4156-98f8-afc248e483a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load into memory\n",
    "# TODO: Test model\n",
    "# TODO: Compare to the current best models for each performance metric, replacing if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0b138b-fd0e-413a-a742-cf8eca95bf1c",
   "metadata": {},
   "source": [
    "## 4. Save best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045ca249-e3f2-451f-93d7-a7d19bc60684",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_filename: str = \"best_models.csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
