{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9cf36ce-0409-4b25-a3a1-d77c4a7a6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from typing import Dict,List,Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19120f54-8564-4f30-8c26-1832f31141f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, device(type='cuda', index=0))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Simulate the args like in the `main_*.py` files\n",
    "class ARGS:\n",
    "    # federated arguments\n",
    "    # epochs:int = 1000         # rounds of training\n",
    "    epochs: int = 10  # rounds of training\n",
    "    train_test_same: int = 0  # use same testing for\n",
    "    num_users: int = 100  # number of users: K\n",
    "    shard_per_user: int = 2  # classes per user\n",
    "    frac: float = 0.1  # the fraction of clients: C\n",
    "    local_ep: int = 1  # the number of local epochs: E\n",
    "    local_bs: int = 10  # local batch size: B\n",
    "    bs: int = 128  # test batch size\n",
    "    lr: float = 0.01  # learning rate\n",
    "    # results_save:str = \"run1\"\n",
    "    momentum: float = 0.5  # SGD momentum (default: 0.5)\n",
    "    # gpu:int = 0\n",
    "    split: str = \"user\"  # train-test split type, user or sample\n",
    "    # grad_norm:str           # use_gradnorm_avging\n",
    "    local_ep_pretrain: int = 0  # the number of pretrain local ep\n",
    "    lr_decay: float = 1.0  # learning rate decay per round\n",
    "\n",
    "    # model arguments\n",
    "    model: str = \"cnn\"  # model name\n",
    "    kernel_num: int = 9  # number of each kind of kernel\n",
    "    kernel_sizes: str = \"3,4,5\"  # comma-separated kernel size to use for convolution\n",
    "    norm: str = \"batch_norm\"  # batch_norm, layer_norm, or None\n",
    "    num_filters: int = 32  # number of filters for conv nets\n",
    "    max_pool: str = True  # whether use max pooling rather than strided convolutions\n",
    "    num_layers_keep: int = 1  # number layers to keep\n",
    "\n",
    "    # other arguments\n",
    "    dataset: str = \"coba\"  # name of dataset\n",
    "    log_level: str = \"warning\"  # level of logger\n",
    "    iid: bool = True  # \"store_true\" #whether iid or not\n",
    "    num_classes: int = 14  # number of classes\n",
    "    num_channels: int = 3  # number of channels of images RGB\n",
    "    gpu: int = 0  # GPU ID, -1 for CPU\n",
    "    stopping_rounds: int = 10  # rounds of early stopping\n",
    "    verbose: bool = True  # \"store_true\"\n",
    "    print_freq: int = 100  # print loss frequency during training\n",
    "    seed: int = 1  # random seed (default:1)\n",
    "    test_freq: int = 1  # how often to test on val set\n",
    "    load_fed: str = \"\"  # define pretrained federated model path\n",
    "    results_save: str = \"run1\"  # define fed results save folder\n",
    "    start_saving: int = 0  # when to start saving models\n",
    "\n",
    "\n",
    "args = ARGS()\n",
    "\n",
    "args.device = torch.device(\n",
    "    \"cuda:{}\".format(args.gpu)\n",
    "    if torch.cuda.is_available() and args.gpu != -1\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "args.num_users, args.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff47941-b000-455b-a3e2-6b7be0e2db3e",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5cd7592-6100-4a6a-b3e3-c4b5f7835d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.num_users = 98\n",
    "# args.frac = \"0.3\"\n",
    "# args.results_save = \"coba_fedavg_bestcase_run2\"\n",
    "# args.frac = \"0.5\";args.results_save = \"coba_fedavg_averagecase_run2\"\n",
    "# args.frac = \"1.0\";args.results_save = \"coba_fedavg_worstcase_run2\"\n",
    "args.iid = False\n",
    "args.log_level = \"info\"  # \"debug\" might crash the notebook\n",
    "args.dataset = \"mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fd67a52-fddc-4931-8954-285242a4f705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/mnist')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment_run_dir: Path = Path(Path.cwd().parent, \"save\", \"coba_legacy\")\n",
    "AS_PDF:bool = True\n",
    "experiment_run_dir: Path = Path(Path.cwd().parent, \"save\", args.dataset)\n",
    "async_fl_scenarios: Dict[str, str] = {\"0.3\": \"best\", \"0.5\": \"average\", \"1.0\": \"worst\"}\n",
    "experiment_run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee96f1d9-195e-44e5-b8a1-0fcd192068ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR MNIST\n",
    "# experiment_seed in (0,1,2,3,4,5,6,7,8,9,10,13)\n",
    "# scenario in (\"best\",\"average\",\"worst\"):\n",
    "\n",
    "# experiment_seed = 0\n",
    "# scenario = \"best\"\n",
    "seeds: Tuple[int] = (0,) # if not LEGACY else (0,1,2,3,4,5,6,7,8,9,10,13)\n",
    "# for experiment_seed in (0,1,2,3,4,5,6,7,8,9,10,13):\n",
    "for experiment_seed in seeds:\n",
    "    scenarios_experiment_csv_files:List[Tuple[str,Path]] = []\n",
    "    \n",
    "    for scenario in (\"best\",\"average\",\"worst\"):\n",
    "        base_dir = None\n",
    "        for dir in experiment_run_dir.glob(\"*\"):\n",
    "            scenario_percent: str = (\n",
    "                dir.as_posix().split(os.sep)[-1].split(\"_\")[-2].replace(\"C\", \"\")\n",
    "            )\n",
    "            # print(f\"\\t{scenario_percent} -> {async_fl_scenarios[scenario_percent]}\")\n",
    "            \n",
    "            if async_fl_scenarios[scenario_percent] == scenario:\n",
    "                chosen_scenario_dir = dir\n",
    "            \n",
    "        all_chosen_scenario_runs_dir: Path = Path(chosen_scenario_dir, \"shard2\")\n",
    "        for dir in all_chosen_scenario_runs_dir.glob(\"*\"):\n",
    "            seed: int = int(dir.as_posix().split(os.sep)[-1].split(\"_\")[0].split(\"d\")[-1])\n",
    "        \n",
    "            if experiment_seed == seed:\n",
    "                base_dir = Path(dir)\n",
    "        \n",
    "        # Raise error if no directory is found with the given SEED\n",
    "        if base_dir is None:\n",
    "            raise FileNotFoundError(f\"Directory with the provided seed '{experiment_seed}' does not exist. Please choose a different one and try again.\")\n",
    "        scenario_results_csv:Path = Path(base_dir, \"fed\",\"results.csv\")\n",
    "        # print(f\"{scenario_results_csv.as_posix()} exists: {scenario_results_csv.exists()}\")\n",
    "        scenarios_experiment_csv_files.append((scenario.title(), scenario_results_csv))\n",
    "    \n",
    "    dfs:List[pd.DataFrame] = []\n",
    "    \n",
    "    for scenario, filepath in scenarios_experiment_csv_files:\n",
    "        df = pd.read_csv(filepath, delimiter=\",\")\n",
    "        df = df.assign(scenario=[scenario]*len(df))\n",
    "        dfs.append(df)\n",
    "    \n",
    "    scenario_graphs_dir: Path = Path(Path.cwd(), args.dataset, f\"seed{experiment_seed}_scenario_metrics\")\n",
    "    scenario_graphs_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    col_names:List[str] = [col_name for col_name in dfs[0].columns.values if col_name not in (\"epoch\",\"scenario\")]\n",
    "    plot_titles:Dict[str,str] = {\n",
    "        \"acc\":\"Accuracy\",\n",
    "        \"f1\":\"F1-Score\",\n",
    "        \"loss_avg\":\"Average Loss\",\n",
    "    }\n",
    "    \n",
    "    for col_name in col_names:\n",
    "        # graph_save_file: Path = Path(scenario_graphs_dir, f\"{col_name.title()}.png\")\n",
    "        graph_save_file: Path = Path(scenario_graphs_dir, f\"{col_name.title()}.{'pdf' if AS_PDF else 'png'}\")\n",
    "        \n",
    "        # fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        palettes = [sns.color_palette(\"bright\",n_colors=1),sns.color_palette(\"Dark2\",n_colors=1),sns.color_palette(\"magma\",n_colors=1)]\n",
    "        markers = [\"v\",\"P\",\"d\"]\n",
    "        \n",
    "        for palette, marker, df in zip(palettes,markers,dfs):\n",
    "            epochs = np.arange(len(df) // 10) * 10\n",
    "            adjusted_col = df.groupby(np.arange(len(df)) // 10)[col_name].mean().values  # averaged every 10 epochs\n",
    "            hue = df[\"scenario\"].values[:100]\n",
    "\n",
    "            plot_title:str = plot_titles.get(col_name.replace(\"_test\",\"\"), col_name.replace(\"_test\",\"\")).title()\n",
    "\n",
    "            sns.set_style(\"ticks\", {\"grid.linestyle\":\"-.\"})\n",
    "            # sns.set_style(\"dark\", {\"grid.color\":\"0.6\",\"grid.linestyle\":\"-.\"})\n",
    "\n",
    "\n",
    "            # graph line (0.7 opacity)\n",
    "            sns.lineplot(x=epochs,\n",
    "                         y=adjusted_col,\n",
    "                         hue=hue, \n",
    "                         palette=palette, \n",
    "                         legend=True,\n",
    "                         alpha=0.7,\n",
    "                         ax=ax,\n",
    "            ).set(\n",
    "                            title=plot_title,\n",
    "                            xlabel=\"Epochs\",\n",
    "                            ylabel=\"Value\"\n",
    "            )\n",
    "            \n",
    "            # graph markers (no opacity)\n",
    "            lineplot_markers = sns.lineplot(x=epochs,\n",
    "                         y=adjusted_col,\n",
    "                         linestyle=\"\",\n",
    "                         marker=marker,\n",
    "                         markerfacecolor=palette[0],\n",
    "                         # hue=hue,\n",
    "                         # palette=palette,\n",
    "                         markersize=4,\n",
    "                         legend=True,\n",
    "                         alpha=1,\n",
    "                         ax=ax\n",
    "            )\n",
    "\n",
    "            plt.legend(frameon=True, framealpha=1).get_frame().set_facecolor(\"white\")\n",
    "\n",
    "            for handler, legend_marker in zip(lineplot_markers.legend_.legend_handles, markers):\n",
    "                handler.set_marker(legend_marker)\n",
    "\n",
    "            \n",
    "            plt.grid()\n",
    "            \n",
    "            plt.savefig(graph_save_file)\n",
    "\n",
    "        plt.close()\n",
    "            # plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ff6d85-a33e-4a30-9884-dbfcd7cd32e5",
   "metadata": {},
   "source": [
    "## CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19cf666d-2438-4a84-bc5f-9f6be3e677e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.num_users = 98\n",
    "# args.frac = \"0.3\"\n",
    "# args.results_save = \"coba_fedavg_bestcase_run2\"\n",
    "# args.frac = \"0.5\";args.results_save = \"coba_fedavg_averagecase_run2\"\n",
    "# args.frac = \"1.0\";args.results_save = \"coba_fedavg_worstcase_run2\"\n",
    "args.iid = False\n",
    "args.log_level = \"info\"  # \"debug\" might crash the notebook\n",
    "args.dataset = \"cifar10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31202c7a-c366-4828-b86e-97e1b5ee3ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/cifar10')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment_run_dir: Path = Path(Path.cwd().parent, \"save\", \"coba_legacy\")\n",
    "AS_PDF:bool = True\n",
    "experiment_run_dir: Path = Path(Path.cwd().parent, \"save\", args.dataset)\n",
    "async_fl_scenarios: Dict[str, str] = {\"0.3\": \"best\", \"0.5\": \"average\", \"1.0\": \"worst\"}\n",
    "experiment_run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ad66a3e-b582-4624-a347-80349c27e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR CIFAR10\n",
    "# experiment_seed in (0,1,2,3,4,5,6,7,8,9,10,13)\n",
    "# scenario in (\"best\",\"average\",\"worst\"):\n",
    "\n",
    "# experiment_seed = 0\n",
    "# scenario = \"best\"\n",
    "seeds: Tuple[int] = (10,) # if not LEGACY else (0,1,2,3,4,5,6,7,8,9,10,13)\n",
    "# for experiment_seed in (0,1,2,3,4,5,6,7,8,9,10,13):\n",
    "for experiment_seed in seeds:\n",
    "    scenarios_experiment_csv_files:List[Tuple[str,Path]] = []\n",
    "    \n",
    "    for scenario in (\"best\",\"average\",\"worst\"):\n",
    "        base_dir = None\n",
    "        for dir in experiment_run_dir.glob(\"*\"):\n",
    "            scenario_percent: str = (\n",
    "                dir.as_posix().split(os.sep)[-1].split(\"_\")[-2].replace(\"C\", \"\")\n",
    "            )\n",
    "            # print(f\"\\t{scenario_percent} -> {async_fl_scenarios[scenario_percent]}\")\n",
    "            \n",
    "            if async_fl_scenarios[scenario_percent] == scenario:\n",
    "                chosen_scenario_dir = dir\n",
    "            \n",
    "        all_chosen_scenario_runs_dir: Path = Path(chosen_scenario_dir, \"shard2\")\n",
    "        for dir in all_chosen_scenario_runs_dir.glob(\"*\"):\n",
    "            seed: int = int(dir.as_posix().split(os.sep)[-1].split(\"_\")[0].split(\"d\")[-1])\n",
    "        \n",
    "            if experiment_seed == seed:\n",
    "                base_dir = Path(dir)\n",
    "        \n",
    "        # Raise error if no directory is found with the given SEED\n",
    "        if base_dir is None:\n",
    "            raise FileNotFoundError(f\"Directory with the provided seed '{experiment_seed}' does not exist. Please choose a different one and try again.\")\n",
    "        scenario_results_csv:Path = Path(base_dir, \"fed\",\"results.csv\")\n",
    "        # print(f\"{scenario_results_csv.as_posix()} exists: {scenario_results_csv.exists()}\")\n",
    "        scenarios_experiment_csv_files.append((scenario.title(), scenario_results_csv))\n",
    "    \n",
    "    dfs:List[pd.DataFrame] = []\n",
    "    \n",
    "    for scenario, filepath in scenarios_experiment_csv_files:\n",
    "        df = pd.read_csv(filepath, delimiter=\",\")\n",
    "        df = df.assign(scenario=[scenario]*len(df))\n",
    "        dfs.append(df)\n",
    "    \n",
    "    scenario_graphs_dir: Path = Path(Path.cwd(), args.dataset, f\"seed{experiment_seed}_scenario_metrics\")\n",
    "    scenario_graphs_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    col_names:List[str] = [col_name for col_name in dfs[0].columns.values if col_name not in (\"epoch\",\"scenario\")]\n",
    "    plot_titles:Dict[str,str] = {\n",
    "        \"acc\":\"Accuracy\",\n",
    "        \"f1\":\"F1-Score\",\n",
    "        \"loss_avg\":\"Average Loss\",\n",
    "    }\n",
    "    \n",
    "    for col_name in col_names:\n",
    "        # graph_save_file: Path = Path(scenario_graphs_dir, f\"{col_name.title()}.png\")\n",
    "        graph_save_file: Path = Path(scenario_graphs_dir, f\"{col_name.title()}.{'pdf' if AS_PDF else 'png'}\")\n",
    "        \n",
    "        # fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        palettes = [sns.color_palette(\"bright\",n_colors=1),sns.color_palette(\"Dark2\",n_colors=1),sns.color_palette(\"magma\",n_colors=1)]\n",
    "        markers = [\"v\",\"P\",\"d\"]\n",
    "        \n",
    "        for palette, marker, df in zip(palettes,markers,dfs):\n",
    "            epochs = np.arange(len(df) // 10) * 10\n",
    "            adjusted_col = df.groupby(np.arange(len(df)) // 10)[col_name].mean().values  # averaged every 10 epochs\n",
    "            hue = df[\"scenario\"].values[:100]\n",
    "\n",
    "            plot_title:str = plot_titles.get(col_name.replace(\"_test\",\"\"), col_name.replace(\"_test\",\"\")).title()\n",
    "\n",
    "            sns.set_style(\"ticks\", {\"grid.linestyle\":\"-.\"})\n",
    "            # sns.set_style(\"dark\", {\"grid.color\":\"0.6\",\"grid.linestyle\":\"-.\"})\n",
    "\n",
    "\n",
    "            # graph line (0.7 opacity)\n",
    "            sns.lineplot(x=epochs,\n",
    "                         y=adjusted_col,\n",
    "                         hue=hue, \n",
    "                         palette=palette, \n",
    "                         legend=True,\n",
    "                         alpha=0.7,\n",
    "                         ax=ax,\n",
    "            ).set(\n",
    "                            title=plot_title,\n",
    "                            xlabel=\"Epochs\",\n",
    "                            ylabel=\"Value\"\n",
    "            )\n",
    "            \n",
    "            # graph markers (no opacity)\n",
    "            lineplot_markers = sns.lineplot(x=epochs,\n",
    "                         y=adjusted_col,\n",
    "                         linestyle=\"\",\n",
    "                         marker=marker,\n",
    "                         markerfacecolor=palette[0],\n",
    "                         # hue=hue,\n",
    "                         # palette=palette,\n",
    "                         markersize=4,\n",
    "                         legend=True,\n",
    "                         alpha=1,\n",
    "                         ax=ax\n",
    "            )\n",
    "\n",
    "            plt.legend(frameon=True, framealpha=1).get_frame().set_facecolor(\"white\")\n",
    "\n",
    "            for handler, legend_marker in zip(lineplot_markers.legend_.legend_handles, markers):\n",
    "                handler.set_marker(legend_marker)\n",
    "\n",
    "            \n",
    "            plt.grid()\n",
    "            \n",
    "            plt.savefig(graph_save_file)\n",
    "\n",
    "        plt.close()\n",
    "            # plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e1d389-70db-420a-93d4-c5ab1234a423",
   "metadata": {},
   "source": [
    "## COBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3d02fab-3553-4de0-bf03-54b5d983d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_users = 98\n",
    "# args.frac = \"0.3\"\n",
    "# args.results_save = \"coba_fedavg_bestcase_run2\"\n",
    "# args.frac = \"0.5\";args.results_save = \"coba_fedavg_averagecase_run2\"\n",
    "# args.frac = \"1.0\";args.results_save = \"coba_fedavg_worstcase_run2\"\n",
    "args.iid = False\n",
    "args.log_level = \"info\"  # \"debug\" might crash the notebook\n",
    "args.seed = 0\n",
    "args.dataset = \"coba\"\n",
    "\n",
    "# base_dir: Path = Path(\n",
    "#     Path.cwd().parent,\n",
    "#     \"save\",\n",
    "#     \"coba_legacy\",\n",
    "#     f\"{args.model}_iid{args.iid}_num{args.num_users}_C{args.frac}_le{args.local_ep}\",\n",
    "#     f\"shard{args.shard_per_user}\",\n",
    "# )\n",
    "\n",
    "# base_dir = Path(base_dir, f\"seed{args.seed}_{args.results_save}\")\n",
    "# # coba_results_df: pd.DataFrame = pd.read_csv(coba_results_path, delimiter=\",\")\n",
    "# # coba_results_df\n",
    "# base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "deecf512-7f95-4d8e-b4be-109f55e2cdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment_run_dir: Path = Path(Path.cwd().parent, \"save\", \"coba_legacy\")\n",
    "LEGACY:bool = True\n",
    "AS_PDF:bool = True\n",
    "experiment_run_dir: Path = Path(Path.cwd().parent, \"save\", args.dataset if not LEGACY else \"coba_legacy\")\n",
    "async_fl_scenarios: Dict[str, str] = {\"0.3\": \"best\", \"0.5\": \"average\", \"1.0\": \"worst\"}\n",
    "experiment_run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ccb58db-cc28-4d4e-b0f6-4ec8f985406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR COBA\n",
    "# experiment_seed in (0,1,2,3,4,5,6,7,8,9,10,13)\n",
    "# scenario in (\"best\",\"average\",\"worst\"):\n",
    "\n",
    "# experiment_seed = 0\n",
    "# scenario = \"best\"\n",
    "seeds: Tuple[int] = (250,750) if not LEGACY else (0,1,2,3,4,5,6,7,8,9,10,13)\n",
    "# for experiment_seed in (0,1,2,3,4,5,6,7,8,9,10,13):\n",
    "for experiment_seed in seeds:\n",
    "    scenarios_experiment_csv_files:List[Tuple[str,Path]] = []\n",
    "    \n",
    "    for scenario in (\"best\",\"average\",\"worst\"):\n",
    "        base_dir = None\n",
    "        for dir in experiment_run_dir.glob(\"*\"):\n",
    "            scenario_percent: str = (\n",
    "                dir.as_posix().split(os.sep)[-1].split(\"_\")[-2].replace(\"C\", \"\")\n",
    "            )\n",
    "            # print(f\"\\t{scenario_percent} -> {async_fl_scenarios[scenario_percent]}\")\n",
    "            \n",
    "            if async_fl_scenarios[scenario_percent] == scenario:\n",
    "                chosen_scenario_dir = dir\n",
    "            \n",
    "        all_chosen_scenario_runs_dir: Path = Path(chosen_scenario_dir, \"shard2\")\n",
    "        for dir in all_chosen_scenario_runs_dir.glob(\"*\"):\n",
    "            seed: int = int(dir.as_posix().split(os.sep)[-1].split(\"_\")[0].split(\"d\")[-1])\n",
    "        \n",
    "            if experiment_seed == seed:\n",
    "                base_dir = Path(dir)\n",
    "        \n",
    "        # Raise error if no directory is found with the given SEED\n",
    "        if base_dir is None:\n",
    "            raise FileNotFoundError(f\"Directory with the provided seed '{experiment_seed}' does not exist. Please choose a different one and try again.\")\n",
    "        scenario_results_csv:Path = Path(base_dir, \"fed\",\"results.csv\")\n",
    "        # print(f\"{scenario_results_csv.as_posix()} exists: {scenario_results_csv.exists()}\")\n",
    "        scenarios_experiment_csv_files.append((scenario.title(), scenario_results_csv))\n",
    "    \n",
    "    dfs:List[pd.DataFrame] = []\n",
    "    \n",
    "    for scenario, filepath in scenarios_experiment_csv_files:\n",
    "        df = pd.read_csv(filepath, delimiter=\",\")\n",
    "        df = df.assign(scenario=[scenario]*len(df))\n",
    "        dfs.append(df)\n",
    "    \n",
    "    scenario_graphs_dir: Path = Path(Path.cwd(), args.dataset, f\"seed{experiment_seed}_scenario_metrics\")\n",
    "    scenario_graphs_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    col_names:List[str] = [col_name for col_name in dfs[0].columns.values if col_name not in (\"epoch\",\"scenario\")]\n",
    "    plot_titles:Dict[str,str] = {\n",
    "        \"acc\":\"Accuracy\",\n",
    "        \"f1\":\"F1-Score\",\n",
    "        \"loss_avg\":\"Average Loss\",\n",
    "    }\n",
    "    \n",
    "    for col_name in col_names:\n",
    "        # graph_save_file: Path = Path(scenario_graphs_dir, f\"{col_name.title()}.png\")\n",
    "        graph_save_file: Path = Path(scenario_graphs_dir, f\"{col_name.title()}.{'pdf' if AS_PDF else 'png'}\")\n",
    "        \n",
    "        # fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        palettes = [sns.color_palette(\"bright\",n_colors=1),sns.color_palette(\"Dark2\",n_colors=1),sns.color_palette(\"magma\",n_colors=1)]\n",
    "        markers = [\"v\",\"P\",\"d\"]\n",
    "        \n",
    "        for palette, marker, df in zip(palettes,markers,dfs):\n",
    "            epochs = np.arange(len(df) // 10) * 10\n",
    "            adjusted_col = df.groupby(np.arange(len(df)) // 10)[col_name].mean().values  # averaged every 10 epochs\n",
    "            hue = df[\"scenario\"].values[:100]\n",
    "\n",
    "            plot_title:str = plot_titles.get(col_name.replace(\"_test\",\"\"), col_name.replace(\"_test\",\"\")).title()\n",
    "\n",
    "            sns.set_style(\"ticks\", {\"grid.linestyle\":\"-.\"})\n",
    "            # sns.set_style(\"dark\", {\"grid.color\":\"0.6\",\"grid.linestyle\":\"-.\"})\n",
    "\n",
    "\n",
    "            # graph line (0.3 opacity)\n",
    "            sns.lineplot(x=epochs,\n",
    "                         y=adjusted_col,\n",
    "                         hue=hue, \n",
    "                         palette=palette, \n",
    "                         legend=True,\n",
    "                         alpha=0.7,\n",
    "                         ax=ax,\n",
    "            ).set(\n",
    "                            title=plot_title,\n",
    "                            xlabel=\"Epochs\",\n",
    "                            ylabel=\"Value\"\n",
    "            )\n",
    "            \n",
    "            # graph markers (no opacity)\n",
    "            lineplot_markers = sns.lineplot(x=epochs,\n",
    "                         y=adjusted_col,\n",
    "                         linestyle=\"\",\n",
    "                         marker=marker,\n",
    "                         markerfacecolor=palette[0],\n",
    "                         # hue=hue,\n",
    "                         # palette=palette,\n",
    "                         markersize=4,\n",
    "                         legend=True,\n",
    "                         alpha=1,\n",
    "                         ax=ax\n",
    "            )\n",
    "\n",
    "            plt.legend(frameon=True, framealpha=1).get_frame().set_facecolor(\"white\")\n",
    "\n",
    "            for handler, legend_marker in zip(lineplot_markers.legend_.legend_handles, markers):\n",
    "                handler.set_marker(legend_marker)\n",
    "\n",
    "            \n",
    "            plt.grid()\n",
    "            \n",
    "            plt.savefig(graph_save_file)\n",
    "\n",
    "        plt.close()\n",
    "            # plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559a6ca0-4d47-4051-8a20-d5b4a71801e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50a61742-64d2-4aaf-ade2-f9cd663710a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs:List[pd.DataFrame] = []\n",
    "\n",
    "for scenario, filepath in scenarios_experiment_csv_files:\n",
    "    df = pd.read_csv(filepath, delimiter=\",\")\n",
    "    df = df.assign(scenario=[scenario]*len(df))\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29b06d9f-8144-4ef3-939f-6b07d2ec8da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import colormaps\n",
    "# list(colormaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e08a54a1-e5ec-49e2-8e44-7545f572b856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg  width=\"55\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#023eff;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "[(0.00784313725490196, 0.24313725490196078, 1.0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.color_palette(\"bright\",n_colors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66cc2313-c3b6-4c1f-9022-b19179cea05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg  width=\"55\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#1b9e77;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "[(0.10588235294117647, 0.6196078431372549, 0.4666666666666667)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sns.color_palette(\"Accent\",n_colors=1)\n",
    "sns.color_palette(palette='Dark2',n_colors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f48e26b8-c378-4607-bdca-c7a7f3bf689e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg  width=\"55\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#b73779;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "[(0.716387, 0.214982, 0.47529)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.color_palette(\"magma\",n_colors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9692b65-bca5-453e-bd3b-1855ac4b7158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_avg\n",
      "loss\n",
      "acc\n",
      "f1\n",
      "precision\n",
      "recall\n",
      "best_acc\n"
     ]
    }
   ],
   "source": [
    "for name in [col_name for col_name in dfs[0].columns.values if col_name not in (\"epoch\",\"scenario\")]:\n",
    "    print(name.replace(\"_test\",\"\"))\n",
    "# [col_name for col_name in dfs[0].columns.values if col_name not in (\"epoch\",\"scenario\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "338b1b45-1063-4979-9953-1d5abade255a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiment_seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scenario_graphs_dir: Path \u001b[38;5;241m=\u001b[39m Path(Path\u001b[38;5;241m.\u001b[39mcwd(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_seed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_scenario_metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m scenario_graphs_dir\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m col_names:List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m [col_name \u001b[38;5;28;01mfor\u001b[39;00m col_name \u001b[38;5;129;01min\u001b[39;00m dfs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mif\u001b[39;00m col_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscenario\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'experiment_seed' is not defined"
     ]
    }
   ],
   "source": [
    "scenario_graphs_dir: Path = Path(Path.cwd(), f\"seed{experiment_seed}_scenario_metrics\")\n",
    "scenario_graphs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "col_names:List[str] = [col_name for col_name in dfs[0].columns.values if col_name not in (\"epoch\",\"scenario\")]\n",
    "for col_name in col_names:\n",
    "    graph_save_file: Path = Path(scenario_graphs_dir, f\"{col_name.title()}.png\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    palettes = [sns.color_palette(\"bright\",n_colors=1),sns.color_palette(\"Accent\",n_colors=1),sns.color_palette(\"magma\",n_colors=1)]\n",
    "    \n",
    "    for palette, df in zip(palettes,dfs):\n",
    "        epochs = np.arange(len(df) // 10) * 10\n",
    "        adjusted_col = df.groupby(np.arange(len(df)) // 10)[col_name].mean().values  # averaged every 10 epochs\n",
    "        hue = df[\"scenario\"].values[:100]\n",
    "    # avg_adjusted_col = (average_scenario_df.groupby(np.arange(len(average_scenario_df)) // 10).mean()[col_name].values)  # averaged every 10 epochs\n",
    "    # worst_adjusted_col = (worst_scenario_df.groupby(np.arange(len(worst_scenario_df)) // 10).mean()[col_name].values)  # averaged every 10 epochs\n",
    "        sns.set_style(\"ticks\", {\"grid.linestyle\":\"-.\"})\n",
    "\n",
    "        sns.lineplot(x=epochs,y=adjusted_col, hue=hue, palette=palette, ax=ax).set(title=col_name.title(),xlabel=\"Epochs\",ylabel=\"Value\")\n",
    "        plt.grid()\n",
    "        # plt.savefig(graph_save_file)\n",
    "        # plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a68db674-e985-4a08-8088-727198ee803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_run_dir: Path = Path(Path.cwd().parent, \"save\", \"coba_legacy\")\n",
    "# async_fl_scenarios: Dict[str, str] = {\"0.3\": \"best\", \"0.5\": \"average\", \"1.0\": \"worst\"}\n",
    "\n",
    "# for experiment_seed in (0,1,2,3,4,5,6,7,8,9,10,13):\n",
    "#     for scenario in (\"best\",\"average\",\"worst\"):\n",
    "#         for dir in experiment_run_dir.glob(\"*\"):\n",
    "#             scenario_percent: str = (\n",
    "#                 dir.as_posix().split(os.sep)[-1].split(\"_\")[-2].replace(\"C\", \"\")\n",
    "#             )\n",
    "#             # print(f\"\\t{scenario_percent} -> {async_fl_scenarios[scenario_percent]}\")\n",
    "        \n",
    "#             if async_fl_scenarios[scenario_percent] == scenario:\n",
    "#                 chosen_scenario_dir = dir\n",
    "\n",
    "#         all_chosen_scenario_runs_dir: Path = Path(chosen_scenario_dir, \"shard2\")\n",
    "#         for dir in all_chosen_scenario_runs_dir.glob(\"*\"):\n",
    "#             seed: int = int(dir.as_posix().split(os.sep)[-1].split(\"_\")[0].split(\"d\")[-1])\n",
    "        \n",
    "#             if experiment_seed == seed:\n",
    "#                 base_dir = Path(dir)\n",
    "        \n",
    "#         # Raise error if no directory is found with the given SEED\n",
    "#         if base_dir is None:\n",
    "#             raise FileNotFoundError(f\"Directory with the provided seed '{SEED}' does not exist. Please choose a different one and try again.\")\n",
    "\n",
    "# TODO: find way to graph results across each scenario (with the SAME seed) together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b06c11-bf80-4699-b4b8-6e789e8ce678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_all_dynamic_model_selection(args):\n",
    "    # experiment_run_dir: Path = Path(Path.cwd(), \"save\", \"coba_legacy\")\n",
    "    experiment_run_dir: Path = Path(Path.cwd().parent, \"save\", \"coba_legacy\")\n",
    "    async_fl_scenarios: Dict[str, str] = {\"0.3\": \"best\", \"0.5\": \"average\", \"1.0\": \"worst\"}\n",
    "\n",
    "    for experiment_seed in (0,1,2,3,4,5,6,7,8,9,10,13):\n",
    "        for scenario in (\"best\",\"average\",\"worst\"):\n",
    "            for dir in experiment_run_dir.glob(\"*\"):\n",
    "                scenario_percent: str = (\n",
    "                    dir.as_posix().split(os.sep)[-1].split(\"_\")[-2].replace(\"C\", \"\")\n",
    "                )\n",
    "                # print(f\"\\t{scenario_percent} -> {async_fl_scenarios[scenario_percent]}\")\n",
    "            \n",
    "                if async_fl_scenarios[scenario_percent] == scenario:\n",
    "                    chosen_scenario_dir = dir\n",
    "\n",
    "            all_chosen_scenario_runs_dir: Path = Path(chosen_scenario_dir, \"shard2\")\n",
    "            for dir in all_chosen_scenario_runs_dir.glob(\"*\"):\n",
    "                seed: int = int(dir.as_posix().split(os.sep)[-1].split(\"_\")[0].split(\"d\")[-1])\n",
    "            \n",
    "                if experiment_seed == seed:\n",
    "                    base_dir = Path(dir)\n",
    "            \n",
    "            # Raise error if no directory is found with the given SEED\n",
    "            if base_dir is None:\n",
    "                raise FileNotFoundError(f\"Directory with the provided seed '{SEED}' does not exist. Please choose a different one and try again.\")\n",
    "            \n",
    "            print(f\"Starting with {base_dir.as_posix()} (seed '{experiment_seed}')\")\n",
    "            # dynamic_model_selector_and_saver(args=args, base_dir=base_dir)\n",
    "            print(f\"Finished with {base_dir.as_posix()} (seed '{experiment_seed}')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
