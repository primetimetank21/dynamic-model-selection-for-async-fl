{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c17936-35dc-4d71-a35f-c350e69d4f16",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5f5ad90-4814-46fe-bd51-44a3783ce348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, List\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from utils.train_utils import get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5a1400-71b5-4daf-845c-92e92b113e0e",
   "metadata": {},
   "source": [
    "# Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce713305-42f6-4642-8766-a78605ba4e98",
   "metadata": {},
   "source": [
    "1. Get paths of models (given a directory)\n",
    "1. Store paths of models\n",
    "1. For each model...\n",
    "   1. Load into memory\n",
    "   2. Test model\n",
    "   3. Compare to the current best models for each performance metric, replacing if necessary\n",
    "1. Save best models to `best_models.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afaa7ca-6c3a-4399-abb1-28fdb3b76018",
   "metadata": {},
   "source": [
    "# Dynamically Selecting the Best Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9d633b-6096-4b58-9115-06330feb2cfb",
   "metadata": {},
   "source": [
    "## 1. Get paths of models (given a directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7d9bae0-962f-4ac2-aa74-7b1137b68174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, device(type='cuda', index=0))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Simulate the args like in the `main_*.py` files\n",
    "class ARGS:\n",
    "    # federated arguments\n",
    "    # epochs:int = 1000         # rounds of training\n",
    "    epochs: int = 10  # rounds of training\n",
    "    train_test_same: int = 0  # use same testing for\n",
    "    num_users: int = 100  # number of users: K\n",
    "    shard_per_user: int = 2  # classes per user\n",
    "    frac: float = 0.1  # the fraction of clients: C\n",
    "    local_ep: int = 1  # the number of local epochs: E\n",
    "    local_bs: int = 10  # local batch size: B\n",
    "    bs: int = 128  # test batch size\n",
    "    lr: float = 0.01  # learning rate\n",
    "    # results_save:str = \"run1\"\n",
    "    momentum: float = 0.5  # SGD momentum (default: 0.5)\n",
    "    # gpu:int = 0\n",
    "    split: str = \"user\"  # train-test split type, user or sample\n",
    "    # grad_norm:str           # use_gradnorm_avging\n",
    "    local_ep_pretrain: int = 0  # the number of pretrain local ep\n",
    "    lr_decay: float = 1.0  # learning rate decay per round\n",
    "\n",
    "    # model arguments\n",
    "    model: str = \"cnn\"  # model name\n",
    "    kernel_num: int = 9  # number of each kind of kernel\n",
    "    kernel_sizes: str = \"3,4,5\"  # comma-separated kernel size to use for convolution\n",
    "    norm: str = \"batch_norm\"  # batch_norm, layer_norm, or None\n",
    "    num_filters: int = 32  # number of filters for conv nets\n",
    "    max_pool: str = True  # whether use max pooling rather than strided convolutions\n",
    "    num_layers_keep: int = 1  # number layers to keep\n",
    "\n",
    "    # other arguments\n",
    "    dataset: str = \"coba\"  # name of dataset\n",
    "    log_level: str = \"info\"  # level of logger\n",
    "    iid: bool = True  # \"store_true\" #whether iid or not\n",
    "    num_classes: int = 14  # number of classes\n",
    "    num_channels: int = 3  # number of channels of images RGB\n",
    "    gpu: int = 0  # GPU ID, -1 for CPU\n",
    "    stopping_rounds: int = 10  # rounds of early stopping\n",
    "    verbose: bool = True  # \"store_true\"\n",
    "    print_freq: int = 100  # print loss frequency during training\n",
    "    seed: int = 1  # random seed (default:1)\n",
    "    test_freq: int = 1  # how often to test on val set\n",
    "    load_fed: str = \"\"  # define pretrained federated model path\n",
    "    results_save: str = \"run1\"  # define fed results save folder\n",
    "    start_saving: int = 0  # when to start saving models\n",
    "\n",
    "\n",
    "args = ARGS()\n",
    "\n",
    "args.device = torch.device(\n",
    "    \"cuda:{}\".format(args.gpu)\n",
    "    if torch.cuda.is_available() and args.gpu != -1\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "args.num_users, args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbc8302-d1bf-4742-a56c-f712bbd52b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIO: str = \"best\"  # the scenario we're interested in\n",
    "SEED: int = 0  # the seed of the experiment we're interested in analyzing\n",
    "chosen_scenario_dir: Optional[Path] = None\n",
    "experiment_run_dir: Path = Path(\n",
    "    Path.cwd().parent, \"save\", \"coba_legacy\"\n",
    ")  # could also be: \"coba\", \"mnist\", \"cifar10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a9436e9-122c-4be3-98f2-ecbba1ea97c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Async FL Scenarios:\n",
      "\t0.3 -> best\n",
      "\t0.5 -> average\n",
      "\t1.0 -> worst\n",
      "Best case scenario directory: '/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1'\n"
     ]
    }
   ],
   "source": [
    "# Get models according to the chosen scenario\n",
    "async_fl_scenarios: Dict[str, str] = {\"0.3\": \"best\", \"0.5\": \"average\", \"1.0\": \"worst\"}\n",
    "\n",
    "print(\"Async FL Scenarios:\")\n",
    "for dir in experiment_run_dir.glob(\"*\"):\n",
    "    scenario_percent: str = (\n",
    "        dir.as_posix().split(os.sep)[-1].split(\"_\")[-2].replace(\"C\", \"\")\n",
    "    )\n",
    "    print(f\"\\t{scenario_percent} -> {async_fl_scenarios[scenario_percent]}\")\n",
    "\n",
    "    if async_fl_scenarios[scenario_percent] == SCENARIO:\n",
    "        chosen_scenario_dir = dir\n",
    "\n",
    "print(f\"{SCENARIO.title()} case scenario directory: '{chosen_scenario_dir.as_posix()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636294ce-7210-439d-9046-d207bb498b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best_450.pt', 'best_650.pt', 'model_350.pt', 'best_800.pt', 'model_300.pt', 'model_500.pt', 'best_350.pt', 'best_550.pt', 'best_900.pt', 'best_50.pt', 'best_150.pt', 'model_850.pt', 'model_750.pt', 'best_700.pt', 'best_100.pt', 'model_650.pt', 'model_200.pt', 'best_1000.pt', 'model_450.pt', 'model_50.pt', 'best_600.pt', 'best_400.pt', 'best_250.pt', 'model_900.pt', 'best_300.pt', 'model_800.pt', 'model_550.pt', 'model_600.pt', 'best_850.pt', 'best_500.pt', 'model_150.pt', 'best_750.pt', 'model_100.pt', 'model_250.pt', 'model_700.pt', 'model_1000.pt', 'model_400.pt', 'best_200.pt', 'best_950.pt', 'model_950.pt']\n"
     ]
    }
   ],
   "source": [
    "# Get paths to models in the chosen scenario\n",
    "all_chosen_scenario_runs_dir: Path = Path(chosen_scenario_dir, \"shard2\")\n",
    "all_models_dir: Optional[Path] = None\n",
    "\n",
    "for dir in all_chosen_scenario_runs_dir.glob(\"*\"):\n",
    "    seed: int = int(dir.as_posix().split(os.sep)[-1].split(\"_\")[0].split(\"d\")[-1])\n",
    "\n",
    "    if SEED == seed:\n",
    "        all_models_dir = Path(dir, \"fed\")\n",
    "\n",
    "# Raise error if no directory is found with the given SEED\n",
    "if all_models_dir is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Directory with the provided seed '{SEED}' does not exist. Please choose a different one and try again.\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(\n",
    "    [\n",
    "        model_file.as_posix().split(os.sep)[-1]\n",
    "        for model_file in all_models_dir.glob(\"*.pt\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f12f7d-041a-452f-814c-f77c4cf4b174",
   "metadata": {},
   "source": [
    "## 2. Store paths of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96f441c9-f502-43b7-b59e-deb8909050ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_450.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_650.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_350.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_800.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_300.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_500.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_350.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_550.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_900.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_50.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_150.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_850.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_750.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_700.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_100.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_650.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_200.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_1000.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_450.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_50.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_600.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_400.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_250.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_900.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_300.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_800.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_550.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_600.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_850.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_500.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_150.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_750.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_100.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_250.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_700.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_1000.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_400.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_200.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_950.pt'),\n",
       " PosixPath('/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/model_950.pt')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_paths:List[Path] = sorted([model_file for model_file in all_models_dir.glob(\"*.pt\")],key=lambda s: int(s.as_posix().split(os.sep)[-1].split(\"_\")[-1].replace(\".pt\",\"\")))\n",
    "model_paths: List[Path] = [model_file for model_file in all_models_dir.glob(\"*.pt\")]\n",
    "model_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde7041-43b2-423a-82a5-0baa7f69352f",
   "metadata": {},
   "source": [
    "## 3. For each model..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fa2281",
   "metadata": {},
   "source": [
    "1. Load into memory\n",
    "2. Test model\n",
    "3. Compare to the current best models for each performance metric, replacing if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3daa3f9a-283e-4156-98f8-afc248e483a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tank/Coding-Practice/objective3-fl-experiment/dynamic-model-selection-for-async-fl/save/coba_legacy/cnn_iidFalse_num98_C0.3_le1/shard2/seed0_coba_fedavg_bestcase_run2/fed/best_450.pt\n"
     ]
    }
   ],
   "source": [
    "best_models: Dict[str, Path] = {}\n",
    "for model_path in model_paths:\n",
    "    # TODO: Load into memory\n",
    "    model = get_model(args)\n",
    "\n",
    "    model.load_state_dict(\n",
    "        torch.load(model_path)\n",
    "    ) if args.device.type != \"cpu\" else model.load_state_dict(\n",
    "        torch.load(model_state_dict_path, map_location=torch.device(\"cpu\"))\n",
    "    )\n",
    "\n",
    "    # TODO: Test model\n",
    "    # TODO: Compare to the current best models for each performance metric, replacing if necessary\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0b138b-fd0e-413a-a742-cf8eca95bf1c",
   "metadata": {},
   "source": [
    "## 4. Save best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "045ca249-e3f2-451f-93d7-a7d19bc60684",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_filename: str = \"best_models.csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
